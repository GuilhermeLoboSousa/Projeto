{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting peptide antibiofilm potential\n",
    "\n",
    "For now, we are just reproducing the work of Bose et al. 2022.\n",
    "Code and data available at https://github.com/davidanastasiu/antibiofilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Pickle package\n",
    "import pickle\n",
    "\n",
    "# Packages for visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(font_scale=1.2)\n",
    "# Allows charts to appear in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "path = Path.cwd() #go search for a path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Seq</th>\n",
       "      <th>SeqL</th>\n",
       "      <th>MwWt</th>\n",
       "      <th>Aromaticity</th>\n",
       "      <th>isoelectric point</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>...</th>\n",
       "      <th>_HydrophobicityD2001</th>\n",
       "      <th>_HydrophobicityD2025</th>\n",
       "      <th>_HydrophobicityD2050</th>\n",
       "      <th>_HydrophobicityD2075</th>\n",
       "      <th>_HydrophobicityD2100</th>\n",
       "      <th>_HydrophobicityD3001</th>\n",
       "      <th>_HydrophobicityD3025</th>\n",
       "      <th>_HydrophobicityD3050</th>\n",
       "      <th>_HydrophobicityD3075</th>\n",
       "      <th>_HydrophobicityD3100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|P40505|61-130</td>\n",
       "      <td>0</td>\n",
       "      <td>QYARQVRDLEEERDLELVRLRLFEEYRVSRSGIEFQEDIEKAKAEH...</td>\n",
       "      <td>70</td>\n",
       "      <td>8610.7265</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>5.957659</td>\n",
       "      <td>4.286</td>\n",
       "      <td>11.429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.857</td>\n",
       "      <td>37.143</td>\n",
       "      <td>45.714</td>\n",
       "      <td>65.714</td>\n",
       "      <td>85.714</td>\n",
       "      <td>8.571</td>\n",
       "      <td>25.714</td>\n",
       "      <td>47.143</td>\n",
       "      <td>74.286</td>\n",
       "      <td>97.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|P40505|131-135</td>\n",
       "      <td>0</td>\n",
       "      <td>ERLLM</td>\n",
       "      <td>5</td>\n",
       "      <td>660.8262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.101802</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|Q6GIL6|1-70</td>\n",
       "      <td>0</td>\n",
       "      <td>MRTPIIAGNWKMNKTVQEAKDFVNALPTLPDSKEVESVICAPAIQL...</td>\n",
       "      <td>70</td>\n",
       "      <td>7576.6359</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>5.179817</td>\n",
       "      <td>12.857</td>\n",
       "      <td>1.429</td>\n",
       "      <td>5.714</td>\n",
       "      <td>...</td>\n",
       "      <td>4.286</td>\n",
       "      <td>27.143</td>\n",
       "      <td>58.571</td>\n",
       "      <td>74.286</td>\n",
       "      <td>98.571</td>\n",
       "      <td>1.429</td>\n",
       "      <td>17.143</td>\n",
       "      <td>41.429</td>\n",
       "      <td>62.857</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|Q6GIL6|71-140</td>\n",
       "      <td>0</td>\n",
       "      <td>EDNGAFTGETSPVALADLGVKYVVIGHSERRELFHETDEEINKKAH...</td>\n",
       "      <td>70</td>\n",
       "      <td>7740.4796</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>4.916652</td>\n",
       "      <td>7.143</td>\n",
       "      <td>4.286</td>\n",
       "      <td>2.857</td>\n",
       "      <td>...</td>\n",
       "      <td>5.714</td>\n",
       "      <td>15.714</td>\n",
       "      <td>38.571</td>\n",
       "      <td>72.857</td>\n",
       "      <td>98.571</td>\n",
       "      <td>8.571</td>\n",
       "      <td>25.714</td>\n",
       "      <td>47.143</td>\n",
       "      <td>70.000</td>\n",
       "      <td>84.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|Q6GIL6|141-210</td>\n",
       "      <td>0</td>\n",
       "      <td>ANDVVGEQVKKAVAGLSEDQLKSVVIAYEPIWAIGTGKSSTSEDAN...</td>\n",
       "      <td>70</td>\n",
       "      <td>7443.2487</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>4.575789</td>\n",
       "      <td>12.857</td>\n",
       "      <td>2.857</td>\n",
       "      <td>2.857</td>\n",
       "      <td>...</td>\n",
       "      <td>1.429</td>\n",
       "      <td>24.286</td>\n",
       "      <td>51.429</td>\n",
       "      <td>71.429</td>\n",
       "      <td>97.143</td>\n",
       "      <td>5.714</td>\n",
       "      <td>22.857</td>\n",
       "      <td>44.286</td>\n",
       "      <td>72.857</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>PA-MAP</td>\n",
       "      <td>1</td>\n",
       "      <td>LAAKLTKAATKLTAALTKLAAALT</td>\n",
       "      <td>24</td>\n",
       "      <td>2354.8707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.477740</td>\n",
       "      <td>37.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.333</td>\n",
       "      <td>25.000</td>\n",
       "      <td>54.167</td>\n",
       "      <td>70.833</td>\n",
       "      <td>100.000</td>\n",
       "      <td>4.167</td>\n",
       "      <td>4.167</td>\n",
       "      <td>50.000</td>\n",
       "      <td>66.667</td>\n",
       "      <td>95.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>HSAFP1</td>\n",
       "      <td>1</td>\n",
       "      <td>DGVKLCDVPSGTWSGHCGSSSKCSQQCKDREHFAYGGACHYQFPSV...</td>\n",
       "      <td>54</td>\n",
       "      <td>5948.6696</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>8.490825</td>\n",
       "      <td>3.704</td>\n",
       "      <td>3.704</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.704</td>\n",
       "      <td>22.222</td>\n",
       "      <td>37.037</td>\n",
       "      <td>66.667</td>\n",
       "      <td>83.333</td>\n",
       "      <td>5.556</td>\n",
       "      <td>14.815</td>\n",
       "      <td>50.000</td>\n",
       "      <td>85.185</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>HSLIN06</td>\n",
       "      <td>1</td>\n",
       "      <td>EHFAYGGAKHYQFPSVKKFKKRQK</td>\n",
       "      <td>24</td>\n",
       "      <td>2910.3355</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>10.218835</td>\n",
       "      <td>8.333</td>\n",
       "      <td>4.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.333</td>\n",
       "      <td>16.667</td>\n",
       "      <td>29.167</td>\n",
       "      <td>41.667</td>\n",
       "      <td>62.500</td>\n",
       "      <td>12.500</td>\n",
       "      <td>12.500</td>\n",
       "      <td>54.167</td>\n",
       "      <td>66.667</td>\n",
       "      <td>79.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>Verine</td>\n",
       "      <td>1</td>\n",
       "      <td>RRRWWWWV</td>\n",
       "      <td>8</td>\n",
       "      <td>1330.5430</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.999968</td>\n",
       "      <td>0.000</td>\n",
       "      <td>37.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>62.500</td>\n",
       "      <td>75.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>Phylloseptin-PTa</td>\n",
       "      <td>1</td>\n",
       "      <td>FLSLIPKIAGGIAALAKHL</td>\n",
       "      <td>19</td>\n",
       "      <td>1933.3829</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>10.002802</td>\n",
       "      <td>21.053</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.789</td>\n",
       "      <td>31.579</td>\n",
       "      <td>52.632</td>\n",
       "      <td>68.421</td>\n",
       "      <td>94.737</td>\n",
       "      <td>5.263</td>\n",
       "      <td>10.526</td>\n",
       "      <td>26.316</td>\n",
       "      <td>63.158</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2662 rows × 574 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name  Type  \\\n",
       "0      sp|P40505|61-130     0   \n",
       "1     sp|P40505|131-135     0   \n",
       "2        sp|Q6GIL6|1-70     0   \n",
       "3      sp|Q6GIL6|71-140     0   \n",
       "4     sp|Q6GIL6|141-210     0   \n",
       "...                 ...   ...   \n",
       "2657             PA-MAP     1   \n",
       "2658             HSAFP1     1   \n",
       "2659            HSLIN06     1   \n",
       "2660             Verine     1   \n",
       "2661   Phylloseptin-PTa     1   \n",
       "\n",
       "                                                    Seq  SeqL       MwWt  \\\n",
       "0     QYARQVRDLEEERDLELVRLRLFEEYRVSRSGIEFQEDIEKAKAEH...    70  8610.7265   \n",
       "1                                                 ERLLM     5   660.8262   \n",
       "2     MRTPIIAGNWKMNKTVQEAKDFVNALPTLPDSKEVESVICAPAIQL...    70  7576.6359   \n",
       "3     EDNGAFTGETSPVALADLGVKYVVIGHSERRELFHETDEEINKKAH...    70  7740.4796   \n",
       "4     ANDVVGEQVKKAVAGLSEDQLKSVVIAYEPIWAIGTGKSSTSEDAN...    70  7443.2487   \n",
       "...                                                 ...   ...        ...   \n",
       "2657                           LAAKLTKAATKLTAALTKLAAALT    24  2354.8707   \n",
       "2658  DGVKLCDVPSGTWSGHCGSSSKCSQQCKDREHFAYGGACHYQFPSV...    54  5948.6696   \n",
       "2659                           EHFAYGGAKHYQFPSVKKFKKRQK    24  2910.3355   \n",
       "2660                                           RRRWWWWV     8  1330.5430   \n",
       "2661                                FLSLIPKIAGGIAALAKHL    19  1933.3829   \n",
       "\n",
       "      Aromaticity  isoelectric point       A       R      N  ...  \\\n",
       "0        0.071429           5.957659   4.286  11.429  0.000  ...   \n",
       "1        0.000000           6.101802   0.000  20.000  0.000  ...   \n",
       "2        0.057143           5.179817  12.857   1.429  5.714  ...   \n",
       "3        0.057143           4.916652   7.143   4.286  2.857  ...   \n",
       "4        0.042857           4.575789  12.857   2.857  2.857  ...   \n",
       "...           ...                ...     ...     ...    ...  ...   \n",
       "2657     0.000000          10.477740  37.500   0.000  0.000  ...   \n",
       "2658     0.111111           8.490825   3.704   3.704  0.000  ...   \n",
       "2659     0.208333          10.218835   8.333   4.167  0.000  ...   \n",
       "2660     0.500000          11.999968   0.000  37.500  0.000  ...   \n",
       "2661     0.052632          10.002802  21.053   0.000  0.000  ...   \n",
       "\n",
       "      _HydrophobicityD2001  _HydrophobicityD2025  _HydrophobicityD2050  \\\n",
       "0                    2.857                37.143                45.714   \n",
       "1                    0.000                 0.000                 0.000   \n",
       "2                    4.286                27.143                58.571   \n",
       "3                    5.714                15.714                38.571   \n",
       "4                    1.429                24.286                51.429   \n",
       "...                    ...                   ...                   ...   \n",
       "2657                 8.333                25.000                54.167   \n",
       "2658                 3.704                22.222                37.037   \n",
       "2659                 8.333                16.667                29.167   \n",
       "2660                 0.000                 0.000                 0.000   \n",
       "2661                15.789                31.579                52.632   \n",
       "\n",
       "      _HydrophobicityD2075  _HydrophobicityD2100  _HydrophobicityD3001  \\\n",
       "0                   65.714                85.714                 8.571   \n",
       "1                    0.000                 0.000                60.000   \n",
       "2                   74.286                98.571                 1.429   \n",
       "3                   72.857                98.571                 8.571   \n",
       "4                   71.429                97.143                 5.714   \n",
       "...                    ...                   ...                   ...   \n",
       "2657                70.833               100.000                 4.167   \n",
       "2658                66.667                83.333                 5.556   \n",
       "2659                41.667                62.500                12.500   \n",
       "2660                 0.000                 0.000                50.000   \n",
       "2661                68.421                94.737                 5.263   \n",
       "\n",
       "      _HydrophobicityD3025  _HydrophobicityD3050  _HydrophobicityD3075  \\\n",
       "0                   25.714                47.143                74.286   \n",
       "1                  100.000                60.000                80.000   \n",
       "2                   17.143                41.429                62.857   \n",
       "3                   25.714                47.143                70.000   \n",
       "4                   22.857                44.286                72.857   \n",
       "...                    ...                   ...                   ...   \n",
       "2657                 4.167                50.000                66.667   \n",
       "2658                14.815                50.000                85.185   \n",
       "2659                12.500                54.167                66.667   \n",
       "2660                50.000                62.500                75.000   \n",
       "2661                10.526                26.316                63.158   \n",
       "\n",
       "      _HydrophobicityD3100  \n",
       "0                   97.143  \n",
       "1                  100.000  \n",
       "2                  100.000  \n",
       "3                   84.286  \n",
       "4                  100.000  \n",
       "...                    ...  \n",
       "2657                95.833  \n",
       "2658               100.000  \n",
       "2659                79.167  \n",
       "2660               100.000  \n",
       "2661               100.000  \n",
       "\n",
       "[2662 rows x 574 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "peptides = pd.read_csv('peptides-all.csv', encoding='cp1252') #latin encoding\n",
    "peptides\n",
    "# a total of 2662 peptides, i.e. 242 positive examples and 2420 negative examples\n",
    "#more negative samples taht positive\n",
    "#capacity antibiofilm type=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sp|P40505|61-130' 0\n",
      "  'QYARQVRDLEEERDLELVRLRLFEEYRVSRSGIEFQEDIEKAKAEHEKLIKLCKERLYSSIEQKIKKLQE'\n",
      "  ... 47.143 74.286 97.143]\n",
      " ['sp|P40505|131-135' 0 'ERLLM' ... 60.0 80.0 100.0]\n",
      " ['sp|Q6GIL6|1-70' 0\n",
      "  'MRTPIIAGNWKMNKTVQEAKDFVNALPTLPDSKEVESVICAPAIQLDALTTAVKEGKAQGLEIGAQNTYF'\n",
      "  ... 41.429 62.857 100.0]\n",
      " ...\n",
      " ['HSLIN06' 1 'EHFAYGGAKHYQFPSVKKFKKRQK' ... 54.167 66.667 79.167]\n",
      " ['Verine' 1 'RRRWWWWV' ... 62.5 75.0 100.0]\n",
      " ['Phylloseptin-PTa' 1 'FLSLIPKIAGGIAALAKHL' ... 26.316 63.158 100.0]]\n"
     ]
    }
   ],
   "source": [
    "# X, i.e. the features or attributes\n",
    "characters=peptides.to_numpy() \n",
    "print(characters)\n",
    "#each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# y, i.e. the class attribute where 0=negative and 1=positive\n",
    "type_label=peptides['Type'].to_numpy()\n",
    "print(type_label)\n",
    "#the type existent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common mapping\n",
    "X=characters #rest of data\n",
    "Y=type_label #0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to confirm sequences are ok but otherwise too verbose to run\n",
    "#for rows in X:\n",
    "#    print(str(rows.item(2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERCI: motif discovery\n",
    "\n",
    "Method for find motifs in the sequences and counting the frequencies of each given motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for TRAIN data\n",
    "def call_and_parse_motif_on_train (x_data) :\n",
    "    if os.path.exists(\"pos_train_seq_new.fasta\"):\n",
    "        os.remove(\"pos_train_seq_new.fasta\")\n",
    "    if os.path.exists(\"neg_train_seq_new.fasta\"):\n",
    "        os.remove(\"neg_train_seq_new.fasta\")\n",
    "    if os.path.exists(\"motif_output.occurrences\"):\n",
    "        os.remove(\"motif_output.occurrences\")\n",
    "        \n",
    "    fp= open(\"pos_train_seq_new.fasta\",\"a+\")\n",
    "    fn= open(\"neg_train_seq_new.fasta\",\"a+\")\n",
    "    for rows in x_data:\n",
    "        if(rows.item(1) == 1):\n",
    "            fp.write('>')\n",
    "            fp.write(str(rows.item(0)))\n",
    "            fp.write('\\n')\n",
    "            fp.write((str(rows.item(2))) + '\\n')\n",
    "            #fp.write('\\n')\n",
    "    for rows in x_data:\n",
    "        if(rows.item(1) == 0):\n",
    "            fn.write('>')\n",
    "            fn.write(rows.item(0))\n",
    "            fn.write('\\n')\n",
    "            fn.write((str(rows.item(2)) )+ '\\n')\n",
    "            #fn.write('\\n') \n",
    "    fp.close()  \n",
    "    fn.close()\n",
    "    \n",
    "    #print(\"running motif script\")\n",
    "    #C:\\Strawberry\\perl\\bin\\perl.exe\n",
    "    \n",
    "    cmd_pl=\"perl MERCI-U.pl -p pos_train_seq_new.fasta -n neg_train_seq_new.fasta -o motif_output -k ALL\"\n",
    "    pl_script = subprocess.Popen(cmd_pl)\n",
    "    \n",
    "    pl_script.communicate()\n",
    "    if pl_script.returncode == 0:\n",
    "        print(\"Motif script end, now parsing\")\n",
    "    else:\n",
    "        print(\"Error executing Perl script!!!\")\n",
    "        \n",
    "    occ_file=f\"{path}\\motif_output.occurrences\"\n",
    "    #print(occ_file)\n",
    "    f = open(occ_file, \"r\")\n",
    "    occ_word_list = f.read().split()\n",
    "    f.close()\n",
    "    \n",
    "    #print (x_data.shape)\n",
    "    Xm=x_data[:,3:]\n",
    "    #print (Xm.shape)\n",
    "    N=x_data[:,0].shape\n",
    "    b=np.zeros((N[0],1))\n",
    "    Xm = np.hstack((b, Xm))\n",
    "    i=0\n",
    "    max = 0\n",
    "    for x in x_data:\n",
    "        name='>'+x[0]\n",
    "        #print(x[0])\n",
    "        m=occ_word_list.count(name)\n",
    "        #print(m)\n",
    "        Xm[i,0]=m\n",
    "        #if (m>max):\n",
    "        #    max = m\n",
    "        i=i+1\n",
    "    return Xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test data\n",
    "def call_and_parse_motif_on_test (x_data) :\n",
    "    if os.path.exists(\"pos_test_seq.fasta\"):\n",
    "        os.remove(\"pos_test_seq.fasta\")\n",
    "    if os.path.exists(\"neg_test_seq.fasta\"):\n",
    "        os.remove(\"neg_test_seq.fasta\")\n",
    "    if os.path.exists(\"motif_test_output\"):\n",
    "        os.remove(\"motif_test_output\")\n",
    "    fp= open(\"pos_test_seq.fasta\",\"a+\")\n",
    "    fn= open(\"neg_test_seq.fasta\",\"a+\")\n",
    "    for rows in x_data:\n",
    "        if(rows.item(1) == 1):\n",
    "            fp.write('>')\n",
    "            fp.write(str(rows.item(0)))\n",
    "            fp.write('\\n')\n",
    "            fp.write((str(rows.item(2))) + '\\n')\n",
    "            #fp.write('\\n')\n",
    "    for rows in x_data:\n",
    "        if(rows.item(1) == 0):\n",
    "            fn.write('>')\n",
    "            fn.write(rows.item(0))\n",
    "            fn.write('\\n')\n",
    "            fn.write((str(rows.item(2)) )+ '\\n')\n",
    "            #fn.write('\\n') \n",
    "    fp.close()  \n",
    "    fn.close()\n",
    "    #print(\"running motif script\")\n",
    "    cmd_pl=\"perl MERCI_motif_locator.pl -p pos_test_seq.fasta -n neg_test_seq.fasta -i motif_output -o motif_test_output\"\n",
    "    pl_script = subprocess.Popen(cmd_pl)\n",
    "                     \n",
    "    pl_script.communicate()\n",
    "    #print(\"motif script end, now parsing\")\n",
    "    occ_file=f\"{path}\\motif_test_output\"\n",
    "    f = open(occ_file, \"r\")\n",
    "    occ_word_list = f.read().split()\n",
    "    f.close()\n",
    "\n",
    "    #print (x_data.shape)\n",
    "    Xm=x_data[:,3:]\n",
    "    #print (Xm.shape)\n",
    "    N=x_data[:,0].shape\n",
    "    b=np.zeros((N[0],1))\n",
    "    Xm = np.hstack((b, Xm))\n",
    "    i=0\n",
    "    max=0\n",
    "    for x in x_data:\n",
    "        name='>'+x[0]\n",
    "        #print(x[0])\n",
    "        m=occ_word_list.count(name)\n",
    "        #print(m)\n",
    "        Xm[i,0]=m\n",
    "        #if (m>max):\n",
    "        #    max = m\n",
    "        i=i+1\n",
    "    return Xm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset 80/20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test splitting such that 80% of the dataset goes to training and 20% to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, Y, stratify=Y,  test_size=0.2, random_state=42, shuffle=True)\n",
    "#statify para que a proporção das classe quer no treino como no teste seja igual\n",
    "#aleatoriedade com shuffle\n",
    "#random state 42 #divide na mesma posição é isso?\n",
    "#divide sempre o dataset nos mesmo 80 e nos mesmos 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533, 574)\n",
      "(533,)\n"
     ]
    }
   ],
   "source": [
    "print(X_te.shape)\n",
    "#passamos de 2662 para 533 (são 20%) está ok, as colunas mantem\n",
    "print(y_te.shape) #vais ser um array com 533 numero ou 0 ou 1 sem uma coluna propriamente dita"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1)) \n",
    "#normalize data to after this can compare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of a SVM model with stratitified k-fold sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SS_classifier = svm.SVC(kernel='rbf', C=150, gamma=0.05, probability=True)\n",
    "SS_classifier = svm.SVC(kernel='rbf', C=150, gamma=0.05) #hiperparameters\n",
    "sss = StratifiedKFold(n_splits =10, random_state=42, shuffle=True) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#em todos os split vai se avaliar as métricas\n",
    "sum_SS_f1=0 #metricas de avaliação\n",
    "scores_ss = [] #accuracy\n",
    "mccs_ss = [] #correlação de Matthews pq há um desequilíbrio nas classes binária\n",
    "f1s_ss = []\n",
    "n=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive sample 194\n",
      "negative sample 1935\n",
      "Motif script end, now parsing\n",
      "MCC 0.781074803302132\n",
      "F1 0.7878787878787878\n",
      "*************************************\n",
      "positive sample 194\n",
      "negative sample 1935\n",
      "Motif script end, now parsing\n",
      "MCC 0.847542615169233\n",
      "F1 0.8484848484848484\n",
      "*************************************\n",
      "positive sample 194\n",
      "negative sample 1935\n",
      "Motif script end, now parsing\n",
      "MCC 0.781074803302132\n",
      "F1 0.7878787878787878\n",
      "*************************************\n",
      "positive sample 194\n",
      "negative sample 1935\n",
      "Motif script end, now parsing\n",
      "MCC 0.8195100309119416\n",
      "F1 0.8333333333333333\n",
      "*************************************\n",
      "positive sample 194\n",
      "negative sample 1935\n",
      "Motif script end, now parsing\n",
      "MCC 0.8266413456321215\n",
      "F1 0.8421052631578947\n",
      "*************************************\n",
      "positive sample 194\n",
      "negative sample 1935\n",
      "Motif script end, now parsing\n",
      "MCC 0.8859385267630794\n",
      "F1 0.8947368421052632\n",
      "*************************************\n",
      "positive sample 194\n",
      "negative sample 1935\n",
      "Motif script end, now parsing\n",
      "MCC 0.8853001441193066\n",
      "F1 0.888888888888889\n",
      "*************************************\n",
      "positive sample 194\n",
      "negative sample 1935\n",
      "Motif script end, now parsing\n",
      "MCC 0.823950527860629\n",
      "F1 0.8235294117647058\n",
      "*************************************\n",
      "positive sample 194\n",
      "negative sample 1935\n",
      "Motif script end, now parsing\n",
      "MCC 0.7960859585955498\n",
      "F1 0.8108108108108107\n",
      "*************************************\n",
      "positive sample 194\n",
      "negative sample 1935\n",
      "Motif script end, now parsing\n",
      "MCC 0.7855805792899597\n",
      "F1 0.7999999999999999\n",
      "*************************************\n"
     ]
    }
   ],
   "source": [
    "#sss = StratifiedShuffleSplit(n_splits= 10, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in sss.split(X_tr, y_tr):\n",
    "    positive=0\n",
    "    negative=0\n",
    "    for i in range(y_tr.shape[0]):\n",
    "        if (y_tr[i]):\n",
    "            positive=positive+1\n",
    "        else:\n",
    "            negative=negative+1\n",
    "    print('positive sample', positive)\n",
    "    print('negative sample', negative)\n",
    "    \n",
    "    X_SS_train, X_SS_test, y_SS_train, y_SS_test = X_tr[train_index], X_tr[test_index], y_tr[train_index], y_tr[test_index]\n",
    "    #divisao dentro do treino  de treino , validation acho eu\n",
    "    #counts motifs in sequence and adds an additional column to the training set\n",
    "    X_SS_train_new=call_and_parse_motif_on_train(X_SS_train)\n",
    "    X_SS_train_new = min_max_scaler.fit_transform(X_SS_train_new)\n",
    "    \n",
    "    #counts motifs in sequence and adds an additional column to the test set \n",
    "    X_SS_test_new=call_and_parse_motif_on_test(X_SS_test)\n",
    "    #X_SS_test_new = normalize (X_SS_test_new, max_c, min_c)\n",
    "    X_SS_test_new = min_max_scaler.transform(X_SS_test_new)\n",
    "    #print(\"test size after motif adding\" , X_SS_test_new.shape)\n",
    "    n=n+1\n",
    "    SS_classifier.fit(X_SS_train_new, y_SS_train)\n",
    "    scores_ss.append(SS_classifier.score(X_SS_test_new, y_SS_test))\n",
    "    ypred=(SS_classifier.predict(X_SS_test_new))\n",
    "    mcc=matthews_corrcoef(y_SS_test, ypred)\n",
    "    print(\"MCC\", mcc)\n",
    "    mccs_ss.append (mcc)\n",
    "    #print(\"accuracy\", (SS_classifier.score(X_SS_test_new, y_SS_test)))\n",
    "    f1=f1_score(y_SS_test, ypred)\n",
    "    print(\"F1\", f1)\n",
    "    f1s_ss.append(f1)\n",
    "    print(\"*************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "Scores:  0.9669811320754716 0.9812206572769953 0.005347502901240782\n",
      "F1s:  0.7878787878787878 0.8947368421052632 0.03603532022312803\n",
      "MCCs:  0.781074803302132 0.8859385267630794 0.037564002874547975\n",
      "avg cross-validation accuracy: 0.9722849676676409\n",
      "avg cross-validation f1: 0.8317646974303321\n",
      "avg cross-validation mcc: 0.8232699334946085\n",
      "*************************************\n",
      "Motif script end, now parsing\n",
      "*************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"*************************************\")\n",
    "print(\"Scores: \",np.min(scores_ss), np.max(scores_ss), np.std(scores_ss))\n",
    "print(\"F1s: \", np.min(f1s_ss), np.max(f1s_ss), np.std(f1s_ss))\n",
    "print(\"MCCs: \", np.min(mccs_ss), np.max(mccs_ss), np.std(mccs_ss))\n",
    "print ( \"avg cross-validation accuracy:\", (sum(scores_ss)/10))\n",
    "print ( \"avg cross-validation f1:\", (sum(f1s_ss)/10))\n",
    "print ( \"avg cross-validation mcc:\", (sum(mccs_ss)/10))\n",
    "print(\"*************************************\")\n",
    "\n",
    "#SS_classifier.fit(best_X_SS_train, best_y_SS_train)\n",
    "\n",
    "X_new = call_and_parse_motif_on_train(X_tr)\n",
    "#X_new, max_c, min_c = normalize_and_get_minmax (X_new)\n",
    "X_new = min_max_scaler.fit_transform(X_new)\n",
    "SS_classifier.fit(X_new,y_tr)\n",
    "y_tr_predict = SS_classifier.predict(X_new)\n",
    "\n",
    "print(\"*************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 on Train set:  0.9974160206718347\n",
      "MCC on Train set:  0.9971617192909873\n",
      "tn, fp, tp, fn 1935 0 193 1\n",
      "Specificity on Train set(tn / (tn+fp)):  1.0\n",
      "Sensitivity on Train set(tp / (tp+fn)):  0.9948453608247423\n",
      "Accuracy on Train set:  0.9995302959135745\n"
     ]
    }
   ],
   "source": [
    "print('f1 on Train set: ', f1_score(y_tr, y_tr_predict))\n",
    "print('MCC on Train set: ', matthews_corrcoef(y_tr, y_tr_predict))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_tr, y_tr_predict).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn+fp)\n",
    "print('Specificity on Train set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp+fn)\n",
    "print('Sensitivity on Train set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp+tn) /(tp+tn+fp+fn)\n",
    "print('Accuracy on Train set: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_new = call_and_parse_motif_on_test(X_te)\n",
    "x_test_df = pd.DataFrame(X_te_new)\n",
    "x_test_df.to_csv('x_test1.csv')#sem normlizar\n",
    "X_te_new = min_max_scaler.transform(X_te_new)\n",
    "x_test_df = pd.DataFrame(X_te_new)\n",
    "x_test_df.to_csv('x_test2.csv')\n",
    "y_SS_pred=SS_classifier.predict(X_te_new)\n",
    "\n",
    "#TESTING NEW CODE\n",
    "#for i in range(X_te_new.shape[0]):\n",
    "#    if (y_te[i]):\n",
    "#        if (y_SS_pred[i] != y_te[i]):\n",
    "# print (\"Wrong prediction for object: \", i)\n",
    "#            results = SS_classifier.predict_proba(X_te_new)[i]\n",
    "# print (\"Actual: \", y_te[i])\n",
    "# print (\"Predtiction: \", y_SS_pred[i])\n",
    "# gets a dictionary of {'class_name': probability}\n",
    "#            prob_per_class_dictionary = dict(zip(SS_classifier.classes_, results))\n",
    "# print (prob_per_class_dictionary)\n",
    "\n",
    "#for i in range(X_te_new.shape[0]):\n",
    "#    if (y_te[i]):\n",
    "#        if (y_SS_pred[i] == y_te[i]):\n",
    "#            print (\"Correct prediction for object: \", i)\n",
    "#            results = SS_classifier.predict_proba(X_te_new)[i]\n",
    "#            print (\"Actual: \", y_te[i])\n",
    "#            print (\"Predtiction: \", y_SS_pred[i])\n",
    "#            # gets a dictionary of {'class_name': probability}\n",
    "#            prob_per_class_dictionary = dict(zip(SS_classifier.classes_, results))\n",
    "#            print (prob_per_class_dictionary)\n",
    "#TESTING NEW CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "f1 on Test set:  0.9111111111111111\n",
      "MCC on Test set:  0.9053554370794209\n",
      "tn, fp, tp, fn 484 1 41 7\n",
      "Specificity on Test set(tn / (tn+fp)):  0.9979381443298969\n",
      "Sensitivity on Test set(tp / (tp+fn)):  0.8541666666666666\n",
      "Accuracy on Test set:  0.9849906191369606\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"*************************************\")\n",
    "print('f1 on Test set: ', f1_score(y_te, y_SS_pred))\n",
    "print('MCC on Test set: ', matthews_corrcoef(y_te, y_SS_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_te, y_SS_pred).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn+fp)\n",
    "print('Specificity on Test set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp+fn)\n",
    "print('Sensitivity on Test set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp+tn) /(tp+tn+fp+fn)\n",
    "print('Accuracy on Test set: ', accuracy)\n",
    "\n",
    "filename = 'finalized_model_without_probab.sav'\n",
    "pickle.dump(SS_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest nestimators=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#em todos os split vai se avaliar as métricas\n",
    "sum_SS_f1=0 #metricas de avaliação\n",
    "scores_rf = [] #accuracy\n",
    "mccs_rf = [] #correlação de Matthews pq há um desequilíbrio nas classes binária\n",
    "f1s_rf = []\n",
    "n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.7807583881356304\n",
      "F1: 0.7741935483870968\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.8795025417206831\n",
      "F1: 0.8823529411764706\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.8146681597597366\n",
      "F1: 0.8125000000000001\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.781074803302132\n",
      "F1: 0.7878787878787878\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.847542615169233\n",
      "F1: 0.8484848484848484\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.8859385267630794\n",
      "F1: 0.8947368421052632\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.7590252979875405\n",
      "F1: 0.7499999999999999\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.823950527860629\n",
      "F1: 0.8235294117647058\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.823950527860629\n",
      "F1: 0.8235294117647058\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.9106129237415148\n",
      "F1: 0.9142857142857143\n",
      "*************************************\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(X_tr, y_tr):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for i in range(y_tr.shape[0]):\n",
    "        if y_tr[i] == 1:\n",
    "            positive += 1\n",
    "        else:\n",
    "            negative += 1\n",
    "    print('Positive samples:', positive)\n",
    "    print('Negative samples:', negative)\n",
    "    \n",
    "    X_RF_train, X_RF_test, y_RF_train, y_RF_test = X_tr[train_index], X_tr[test_index], y_tr[train_index], y_tr[test_index]\n",
    "    \n",
    "    # Counts motifs in sequence and adds an additional column to the training set\n",
    "    X_RF_train_new = call_and_parse_motif_on_train(X_RF_train)\n",
    "    X_RF_train_new = min_max_scaler.fit_transform(X_RF_train_new)\n",
    "    \n",
    "    # Counts motifs in sequence and adds an additional column to the test set\n",
    "    X_RF_test_new = call_and_parse_motif_on_test(X_RF_test)\n",
    "    X_RF_test_new = min_max_scaler.transform(X_RF_test_new)\n",
    "    \n",
    "    RF_classifier.fit(X_RF_train_new, y_RF_train)\n",
    "    scores_rf.append(RF_classifier.score(X_RF_test_new, y_RF_test))\n",
    "    y_pred = RF_classifier.predict(X_RF_test_new)\n",
    "    mcc = matthews_corrcoef(y_RF_test, y_pred)\n",
    "    print(\"MCC:\", mcc)\n",
    "    mccs_rf.append(mcc)\n",
    "    f1 = f1_score(y_RF_test, y_pred)\n",
    "    print(\"F1:\", f1)\n",
    "    f1s_rf.append(f1)\n",
    "    print(\"*************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "Scores:  0.9624413145539906 0.9858490566037735 0.006277391757508224\n",
      "F1s:  0.7499999999999999 0.9142857142857143 0.0441758622230055\n",
      "MCCs:  0.7590252979875405 0.9106129237415148 0.042971911441503925\n",
      "avg cross-validation accuracy: 1.9459872442200368\n",
      "avg cross-validation f1: 1.6629138480150913\n",
      "avg cross-validation mcc: 1.6539723647246891\n",
      "*************************************\n",
      "Motif script end, now parsing\n",
      "*************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*************************************\")\n",
    "print(\"Scores: \", np.min(scores_rf), np.max(scores_rf), np.std(scores_rf))\n",
    "print(\"F1s: \", np.min(f1s_rf), np.max(f1s_rf), np.std(f1s_rf))\n",
    "print(\"MCCs: \", np.min(mccs_rf), np.max(mccs_rf), np.std(mccs_rf))\n",
    "print(\"avg cross-validation accuracy:\", (sum(scores_rf) / 10))\n",
    "print(\"avg cross-validation f1:\", (sum(f1s_rf) / 10))\n",
    "print(\"avg cross-validation mcc:\", (sum(mccs_rf) / 10))\n",
    "print(\"*************************************\")\n",
    "\n",
    "\n",
    "X_new = call_and_parse_motif_on_train(X_tr)\n",
    "X_new = min_max_scaler.fit_transform(X_new)\n",
    "RF_classifier.fit(X_new, y_tr)\n",
    "y_tr_predict = RF_classifier.predict(X_new)\n",
    "\n",
    "print(\"*************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 on Train set:  1.0\n",
      "MCC on Train set:  1.0\n",
      "tn, fp, tp, fn 1935 0 194 0\n",
      "Specificity on Train set(tn / (tn+fp)):  1.0\n",
      "Sensitivity on Train set(tp / (tp+fn)):  1.0\n",
      "Accuracy on Train set:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('f1 on Train set: ', f1_score(y_tr, y_tr_predict))\n",
    "print('MCC on Train set: ', matthews_corrcoef(y_tr, y_tr_predict))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_tr, y_tr_predict).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn+fp)\n",
    "print('Specificity on Train set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp+fn)\n",
    "print('Sensitivity on Train set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp+tn) /(tp+tn+fp+fn)\n",
    "print('Accuracy on Train set: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_new = call_and_parse_motif_on_test(X_te)\n",
    "x_test_df = pd.DataFrame(X_te_new)\n",
    "x_test_df.to_csv('x_test1.csv')#sem normlizar\n",
    "X_te_new = min_max_scaler.transform(X_te_new)\n",
    "x_test_df = pd.DataFrame(X_te_new)\n",
    "x_test_df.to_csv('x_test2.csv')\n",
    "y_RF_pred=RF_classifier.predict(X_te_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "f1 on Test set:  0.9090909090909091\n",
      "MCC on Test set:  0.9054339748948275\n",
      "tn, fp, tp, fn 485 0 40 8\n",
      "Specificity on Test set(tn / (tn+fp)):  1.0\n",
      "Sensitivity on Test set(tp / (tp+fn)):  0.8333333333333334\n",
      "Accuracy on Test set:  0.9849906191369606\n"
     ]
    }
   ],
   "source": [
    "print(\"*************************************\")\n",
    "print('f1 on Test set: ', f1_score(y_te, y_RF_pred))\n",
    "print('MCC on Test set: ', matthews_corrcoef(y_te, y_RF_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_te, y_RF_pred).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn+fp)\n",
    "print('Specificity on Test set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp+fn)\n",
    "print('Sensitivity on Test set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp+tn) /(tp+tn+fp+fn)\n",
    "print('Accuracy on Test set: ', accuracy)\n",
    "\n",
    "filename = 'finalized_model_without_probab.sav'\n",
    "pickle.dump(RF_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Crie o classificador Naive Bayes\n",
    "NB_classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#em todos os split vai se avaliar as métricas\n",
    "sum_nb_f1=0 #metricas de avaliação\n",
    "scores_nb = [] #accuracy\n",
    "mccs_nb = [] #correlação de Matthews pq há um desequilíbrio nas classes binária\n",
    "f1s_nb = []\n",
    "n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.4482356086523409\n",
      "F1: 0.49056603773584906\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.6233654873599985\n",
      "F1: 0.6521739130434783\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.4482356086523409\n",
      "F1: 0.49056603773584906\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.6181599577024444\n",
      "F1: 0.6399999999999999\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.5481499551970149\n",
      "F1: 0.5833333333333334\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.5746354438293783\n",
      "F1: 0.5964912280701754\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.6099823642272856\n",
      "F1: 0.64\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.6099823642272856\n",
      "F1: 0.64\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.5517813788776263\n",
      "F1: 0.5882352941176471\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.6057627086830114\n",
      "F1: 0.6274509803921569\n",
      "*************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in sss.split(X_tr, y_tr):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for i in range(y_tr.shape[0]):\n",
    "        if y_tr[i] == 1:\n",
    "            positive += 1\n",
    "        else:\n",
    "            negative += 1\n",
    "    print('Positive samples:', positive)\n",
    "    print('Negative samples:', negative)\n",
    "    \n",
    "    X_NB_train, X_NB_test, y_NB_train, y_NB_test = X_tr[train_index], X_tr[test_index], y_tr[train_index], y_tr[test_index]\n",
    "    \n",
    "    # Counts motifs in sequence and adds an additional column to the training set\n",
    "    X_NB_train_new = call_and_parse_motif_on_train(X_NB_train)\n",
    "    X_NB_train_new = min_max_scaler.fit_transform(X_NB_train_new)\n",
    "    \n",
    "    # Counts motifs in sequence and adds an additional column to the test set\n",
    "    X_NB_test_new = call_and_parse_motif_on_test(X_NB_test)\n",
    "    X_NB_test_new = min_max_scaler.transform(X_NB_test_new)\n",
    "    \n",
    "    NB_classifier.fit(X_NB_train_new, y_NB_train)\n",
    "    scores_nb.append(NB_classifier.score(X_NB_test_new, y_NB_test))\n",
    "    y_pred = NB_classifier.predict(X_NB_test_new)\n",
    "    mcc = matthews_corrcoef(y_NB_test, y_pred)\n",
    "    print(\"MCC:\", mcc)\n",
    "    mccs_nb.append(mcc)\n",
    "    f1 = f1_score(y_NB_test, y_pred)\n",
    "    print(\"F1:\", f1)\n",
    "    f1s_nb.append(f1)\n",
    "    print(\"*************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "Scores:  0.8732394366197183 0.9248826291079812 0.01704442051012662\n",
      "F1s:  0.49056603773584906 0.6521739130434783 0.056915537014944693\n",
      "MCCs:  0.4482356086523409 0.6233654873599985 0.06304488033952133\n",
      "avg cross-validation accuracy: 0.9027748250509345\n",
      "avg cross-validation f1: 0.5948816824428489\n",
      "avg cross-validation mcc: 0.5638290877408727\n",
      "*************************************\n",
      "Motif script end, now parsing\n",
      "*************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*************************************\")\n",
    "print(\"Scores: \", np.min(scores_nb), np.max(scores_nb), np.std(scores_nb))\n",
    "print(\"F1s: \", np.min(f1s_nb), np.max(f1s_nb), np.std(f1s_nb))\n",
    "print(\"MCCs: \", np.min(mccs_nb), np.max(mccs_nb), np.std(mccs_nb))\n",
    "print(\"avg cross-validation accuracy:\", (sum(scores_nb) / 10))\n",
    "print(\"avg cross-validation f1:\", (sum(f1s_nb) / 10))\n",
    "print(\"avg cross-validation mcc:\", (sum(mccs_nb) / 10))\n",
    "print(\"*************************************\")\n",
    "\n",
    "X_new = call_and_parse_motif_on_train(X_tr)\n",
    "X_new = min_max_scaler.fit_transform(X_new)\n",
    "NB_classifier.fit(X_new, y_tr)\n",
    "y_tr_predict = NB_classifier.predict(X_new)\n",
    "\n",
    "print(\"*************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 on Train set:  0.696588868940754\n",
      "MCC on Train set:  0.6983970839807544\n",
      "tn, fp, tp, fn 1766 169 194 0\n",
      "Specificity on Train set(tn / (tn+fp)):  0.9126614987080104\n",
      "Sensitivity on Train set(tp / (tp+fn)):  1.0\n",
      "Accuracy on Train set:  0.9206200093940817\n"
     ]
    }
   ],
   "source": [
    "print('f1 on Train set: ', f1_score(y_tr, y_tr_predict))\n",
    "print('MCC on Train set: ', matthews_corrcoef(y_tr, y_tr_predict))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_tr, y_tr_predict).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn+fp)\n",
    "print('Specificity on Train set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp+fn)\n",
    "print('Sensitivity on Train set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp+tn) /(tp+tn+fp+fn)\n",
    "print('Accuracy on Train set: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_new = call_and_parse_motif_on_test(X_te)\n",
    "x_test_df = pd.DataFrame(X_te_new)\n",
    "x_test_df.to_csv('x_test1.csv')  # sem normalizar\n",
    "\n",
    "X_te_new = min_max_scaler.transform(X_te_new)\n",
    "x_test_df = pd.DataFrame(X_te_new)\n",
    "x_test_df.to_csv('x_test2.csv')  # normalizado\n",
    "\n",
    "y_NB_pred = NB_classifier.predict(X_te_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "f1 on Test set:  0.6131386861313869\n",
      "MCC on Test set:  0.5972228106372099\n",
      "tn, fp, tp, fn 438 47 42 6\n",
      "Specificity on Test set(tn / (tn+fp)):  0.9030927835051547\n",
      "Sensitivity on Test set(tp / (tp+fn)):  0.875\n",
      "Accuracy on Test set:  0.900562851782364\n"
     ]
    }
   ],
   "source": [
    "print(\"*************************************\")\n",
    "print('f1 on Test set: ', f1_score(y_te, y_NB_pred))\n",
    "print('MCC on Test set: ', matthews_corrcoef(y_te, y_NB_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_te, y_NB_pred).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn + fp)\n",
    "print('Specificity on Test set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Sensitivity on Test set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print('Accuracy on Test set: ', accuracy)\n",
    "\n",
    "filename = 'finalized_model_NB.sav'\n",
    "pickle.dump(NB_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT_classifier = DecisionTreeClassifier(random_state=42)\n",
    "#em todos os split vai se avaliar as métricas\n",
    "sum_dt_f1=0 #metricas de avaliação\n",
    "scores_dt = [] #accuracy\n",
    "mccs_dt = [] #correlação de Matthews pq há um desequilíbrio nas classes binária\n",
    "f1s_dt = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.6712397579529541\n",
      "F1: 0.6666666666666666\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.44916842875170565\n",
      "F1: 0.4533333333333333\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.40565262817976494\n",
      "F1: 0.40963855421686746\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.38470256194069535\n",
      "F1: 0.4\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.45515393843475976\n",
      "F1: 0.45945945945945943\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.474192613658045\n",
      "F1: 0.49275362318840576\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.41039920811391667\n",
      "F1: 0.4383561643835617\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.44814741941713154\n",
      "F1: 0.45569620253164556\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.3303858343438636\n",
      "F1: 0.37837837837837834\n",
      "*************************************\n",
      "Positive samples: 194\n",
      "Negative samples: 1935\n",
      "Motif script end, now parsing\n",
      "MCC: 0.5053122040856076\n",
      "F1: 0.4999999999999999\n",
      "*************************************\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(X_tr, y_tr):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for i in range(y_tr.shape[0]):\n",
    "        if y_tr[i] == 1:\n",
    "            positive += 1\n",
    "        else:\n",
    "            negative += 1\n",
    "    print('Positive samples:', positive)\n",
    "    print('Negative samples:', negative)\n",
    "    \n",
    "    X_DT_train, X_DT_test, y_DT_train, y_DT_test = X_tr[train_index], X_tr[test_index], y_tr[train_index], y_tr[test_index]\n",
    "    \n",
    "    # Counts motifs in sequence and adds an additional column to the training set\n",
    "    X_DT_train_new = call_and_parse_motif_on_train(X_DT_train)\n",
    "    X_DT_train_new = min_max_scaler.fit_transform(X_DT_train_new)\n",
    "    \n",
    "    # Counts motifs in sequence and adds an additional column to the test set\n",
    "    X_DT_test_new = call_and_parse_motif_on_test(X_DT_test)\n",
    "    X_DT_test_new = min_max_scaler.transform(X_DT_test_new)\n",
    "    \n",
    "    DT_classifier.fit(X_DT_train_new, y_DT_train)\n",
    "    scores_dt.append(DT_classifier.score(X_DT_test_new, y_DT_test))\n",
    "    y_pred = DT_classifier.predict(X_DT_test_new)\n",
    "    mcc = matthews_corrcoef(y_DT_test, y_pred)\n",
    "    print(\"MCC:\", mcc)\n",
    "    mccs_dt.append(mcc)\n",
    "    f1 = f1_score(y_DT_test, y_pred)\n",
    "    print(\"F1:\", f1)\n",
    "    f1s_dt.append(f1)\n",
    "    print(\"*************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "Scores:  0.7699530516431925 0.9530516431924883 0.04968416296773573\n",
      "F1s:  0.37837837837837834 0.6666666666666666 0.07643254051820599\n",
      "MCCs:  0.3303858343438636 0.6712397579529541 0.08637744610232846\n",
      "avg cross-validation accuracy: 0.817291168394012\n",
      "avg cross-validation f1: 0.4654282382158318\n",
      "avg cross-validation mcc: 0.45343545948784447\n",
      "*************************************\n",
      "Motif script end, now parsing\n"
     ]
    }
   ],
   "source": [
    "print(\"*************************************\")\n",
    "print(\"Scores: \", np.min(scores_dt), np.max(scores_dt), np.std(scores_dt))\n",
    "print(\"F1s: \", np.min(f1s_dt), np.max(f1s_dt), np.std(f1s_dt))\n",
    "print(\"MCCs: \", np.min(mccs_dt), np.max(mccs_dt), np.std(mccs_dt))\n",
    "print(\"avg cross-validation accuracy:\", (sum(scores_dt) / 10))\n",
    "print(\"avg cross-validation f1:\", (sum(f1s_dt) / 10))\n",
    "print(\"avg cross-validation mcc:\", (sum(mccs_dt) / 10))\n",
    "print(\"*************************************\")\n",
    "\n",
    "X_new = call_and_parse_motif_on_train(X_tr)\n",
    "X_new = min_max_scaler.fit_transform(X_new)\n",
    "DT_classifier.fit(X_new, y_tr)\n",
    "y_tr_predict = DT_classifier.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 on Train set:  1.0\n",
      "MCC on Train set:  1.0\n",
      "tn, fp, tp, fn 1935 0 194 0\n",
      "Specificity on Train set(tn / (tn+fp)):  1.0\n",
      "Sensitivity on Train set(tp / (tp+fn)):  1.0\n",
      "Accuracy on Train set:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('f1 on Train set: ', f1_score(y_tr, y_tr_predict))\n",
    "print('MCC on Train set: ', matthews_corrcoef(y_tr, y_tr_predict))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_tr, y_tr_predict).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn+fp)\n",
    "print('Specificity on Train set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp+fn)\n",
    "print('Sensitivity on Train set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp+tn) /(tp+tn+fp+fn)\n",
    "print('Accuracy on Train set: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_new = call_and_parse_motif_on_test(X_te)\n",
    "x_test_df = pd.DataFrame(X_te_new)\n",
    "x_test_df.to_csv('x_test1.csv')  # sem normalizar\n",
    "\n",
    "X_te_new = min_max_scaler.transform(X_te_new)\n",
    "x_test_df = pd.DataFrame(X_te_new)\n",
    "x_test_df.to_csv('x_test2.csv')  # normalizado\n",
    "\n",
    "y_DT_pred = DT_classifier.predict(X_te_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "f1 on Test set:  0.48000000000000004\n",
      "MCC on Test set:  0.4701806142978604\n",
      "tn, fp, tp, fn 400 85 42 6\n",
      "Specificity on Test set(tn / (tn+fp)):  0.8247422680412371\n",
      "Sensitivity on Test set(tp / (tp+fn)):  0.875\n",
      "Accuracy on Test set:  0.8292682926829268\n"
     ]
    }
   ],
   "source": [
    "print(\"*************************************\")\n",
    "print('f1 on Test set: ', f1_score(y_te, y_DT_pred))\n",
    "print('MCC on Test set: ', matthews_corrcoef(y_te, y_DT_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_te, y_DT_pred).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn + fp)\n",
    "print('Specificity on Test set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Sensitivity on Test set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print('Accuracy on Test set: ', accuracy)\n",
    "\n",
    "filename = 'finalized_model_NB.sav'\n",
    "pickle.dump(DT_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_classifier = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#em todos os split vai se avaliar as métricas\n",
    "sum_lr_f1=0 #metricas de avaliação\n",
    "scores_lr = [] #accuracy\n",
    "mccs_lr = [] #correlação de Matthews pq há um desequilíbrio nas classes binária\n",
    "f1s_lr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(X_tr, y_tr):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for i in range(y_tr.shape[0]):\n",
    "        if y_tr[i] == 1:\n",
    "            positive += 1\n",
    "        else:\n",
    "            negative += 1\n",
    "    print('Positive samples:', positive)\n",
    "    print('Negative samples:', negative)\n",
    "    \n",
    "    X_LR_train, X_LR_test, y_LR_train, y_LR_test = X_tr[train_index], X_tr[test_index], y_tr[train_index], y_tr[test_index]\n",
    "    \n",
    "    # Counts motifs in sequence and adds an additional column to the training set\n",
    "    X_LR_train_new = call_and_parse_motif_on_train(X_LR_train)\n",
    "    X_LR_train_new = min_max_scaler.fit_transform(X_LR_train_new)\n",
    "    \n",
    "    # Counts motifs in sequence and adds an additional column to the test set\n",
    "    X_LR_test_new = call_and_parse_motif_on_test(X_LR_test)\n",
    "    X_LR_test_new = min_max_scaler.transform(X_LR_test_new)\n",
    "    \n",
    "    LR_classifier.fit(X_LR_train_new, y_LR_train)\n",
    "    scores_lr.append(LR_classifier.score(X_LR_test_new, y_LR_test))\n",
    "    y_pred = LR_classifier.predict(X_LR_test_new)\n",
    "    mcc = matthews_corrcoef(y_LR_test, y_pred)\n",
    "    print(\"MCC:\", mcc)\n",
    "    mccs_lr.append(mcc)\n",
    "    f1 = f1_score(y_LR_test, y_pred)\n",
    "    print(\"F1:\", f1)\n",
    "    f1s_lr.append(f1)\n",
    "    print(\"*************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*************************************\")\n",
    "print(\"Scores: \", np.min(scores_lr), np.max(scores_lr), np.std(scores_lr))\n",
    "print(\"F1s: \", np.min(f1s_lr), np.max(f1s_lr), np.std(f1s_lr))\n",
    "print(\"MCCs: \", np.min(mccs_lr), np.max(mccs_lr), np.std(mccs_lr))\n",
    "print(\"avg cross-validation accuracy:\", (sum(scores_lr) / 10))\n",
    "print(\"avg cross-validation f1:\", (sum(f1s_lr) / 10))\n",
    "print(\"avg cross-validation mcc:\", (sum(mccs_lr) / 10))\n",
    "print(\"*************************************\")\n",
    "\n",
    "X_new = call_and_parse_motif_on_train(X_tr)\n",
    "X_new = min_max_scaler.fit_transform(X_new)\n",
    "LR_classifier.fit(X_new, y_tr)\n",
    "y_tr_predict = LR_classifier.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('f1 on Train set: ', f1_score(y_tr, y_tr_predict))\n",
    "print('MCC on Train set: ', matthews_corrcoef(y_tr, y_tr_predict))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_tr, y_tr_predict).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn+fp)\n",
    "print('Specificity on Train set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp+fn)\n",
    "print('Sensitivity on Train set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp+tn) /(tp+tn+fp+fn)\n",
    "print('Accuracy on Train set: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_new = call_and_parse_motif_on_test(X_te)\n",
    "x_test_df = pd.DataFrame(X_te_new)\n",
    "x_test_df.to_csv('x_test1.csv')  # sem normalizar\n",
    "\n",
    "X_te_new = min_max_scaler.transform(X_te_new)\n",
    "x_test_df = pd.DataFrame(X_te_new)\n",
    "x_test_df.to_csv('x_test2.csv')  # normalizado\n",
    "\n",
    "y_LR_pred = LR_classifier.predict(X_te_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*************************************\")\n",
    "print('f1 on Test set: ', f1_score(y_te, y_LR_pred))\n",
    "print('MCC on Test set: ', matthews_corrcoef(y_te, y_LR_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_te, y_LR_pred).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn + fp)\n",
    "print('Specificity on Test set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Sensitivity on Test set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print('Accuracy on Test set: ', accuracy)\n",
    "\n",
    "filename = 'finalized_model_NB.sav'\n",
    "pickle.dump(LR_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'EUF06718.1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\guilh\\OneDrive\\Documentos\\GitHub\\Projeto\\antibiofilm.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/guilh/OneDrive/Documentos/GitHub/Projeto/antibiofilm.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/guilh/OneDrive/Documentos/GitHub/Projeto/antibiofilm.ipynb#X52sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# SVM\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/guilh/OneDrive/Documentos/GitHub/Projeto/antibiofilm.ipynb#X52sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#y_svm_pred_prob = SS_classifier.decision_function(X_te)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/guilh/OneDrive/Documentos/GitHub/Projeto/antibiofilm.ipynb#X52sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#fpr_svm, tpr_svm, _ = roc_curve(y_te, y_svm_pred_prob)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/guilh/OneDrive/Documentos/GitHub/Projeto/antibiofilm.ipynb#X52sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#auc_svm = roc_auc_score(y_te, y_svm_pred_prob)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/guilh/OneDrive/Documentos/GitHub/Projeto/antibiofilm.ipynb#X52sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/guilh/OneDrive/Documentos/GitHub/Projeto/antibiofilm.ipynb#X52sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Random Forest\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/guilh/OneDrive/Documentos/GitHub/Projeto/antibiofilm.ipynb#X52sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m y_rf_pred_prob \u001b[39m=\u001b[39m RF_classifier\u001b[39m.\u001b[39;49mpredict_proba(X_te)[:, \u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/guilh/OneDrive/Documentos/GitHub/Projeto/antibiofilm.ipynb#X52sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m fpr_rf, tpr_rf, _ \u001b[39m=\u001b[39m roc_curve(y_te, y_rf_pred_prob)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/guilh/OneDrive/Documentos/GitHub/Projeto/antibiofilm.ipynb#X52sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m auc_rf \u001b[39m=\u001b[39m roc_auc_score(y_te, y_rf_pred_prob)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:850\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    849\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    852\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    853\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 579\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    580\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    581\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\guilh\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'EUF06718.1'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SVM\n",
    "y_svm_pred_prob = SS_classifier.decision_function(X_te)\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_te, y_svm_pred_prob)\n",
    "auc_svm = roc_auc_score(y_te, y_svm_pred_prob)\n",
    "\n",
    "# Random Forest\n",
    "y_rf_pred_prob = RF_classifier.predict_proba(X_te)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_te, y_rf_pred_prob)\n",
    "auc_rf = roc_auc_score(y_te, y_rf_pred_prob)\n",
    "\n",
    "# Plotando as curvas ROC\n",
    "plt.plot(fpr_svm, tpr_svm, label='SVM (AUC = %0.2f)' % auc_svm)\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest (AUC = %0.2f)' % auc_rf)\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Linha diagonal para referência\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
