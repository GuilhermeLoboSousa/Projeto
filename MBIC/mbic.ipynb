{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AntiBiofilm Peptide Research\n",
    "# Department of Computer Science and Engineering, Santa Clara University\n",
    "# Author: Taylor Downey\n",
    "\n",
    "# A python script that uses the optimized hyperparameters found for both \n",
    "# the SVM and the SVR to create a prediction model\n",
    "# Script prints the average RMSE of the full model when run with cross validation\n",
    "# \n",
    "# NOTE: Given the small number of training samples available, the average RMSE \n",
    "# outputted will vary by about +- 5\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#                               Libraries\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#                               Functions\n",
    "# ------------------------------------------------------------------------------\n",
    "def seperatePeptides(peptides, threshold): #recebe dataframe como peptides e um limite para separar esse peptides\n",
    "\n",
    "    columns = ['MBIC'] #vai ser a coluna relevante para a sepração\n",
    "    \n",
    "    filterMBIC = (peptides[columns] <= threshold).all(axis=1)  #se for menor ou igual ao threshold array boleano que indica quais sao e vamos separa por essas\n",
    "    lower_peptides = peptides[filterMBIC]\n",
    "\n",
    "    filterMBIC = (peptides[columns] > threshold).all(axis=1)   # se for maior guardamos essas\n",
    "    upper_peptides = peptides[filterMBIC]\n",
    "    \n",
    "    return lower_peptides, upper_peptides #separaçao\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#                               Variables\n",
    "# ------------------------------------------------------------------------------\n",
    "training_filename = '../../data/mbic_training_data.csv' #local onde esta o csv com mbic data\n",
    "svm_features_filename = 'mbic_svm_forward_selection_features.json' #nao percebo tenho de perguntar à professora!!\n",
    "svr_features_filename = 'mbic_svr_forward_selection_features.json'\n",
    "svr_svm_results = 'full_model_results.txt'\n",
    "\n",
    "# Optimized Hyperparameters\n",
    "svm_c = 10\n",
    "svm_g = 1000\n",
    "svm_pca_comp = 6\n",
    "svm_num_feat = 9\n",
    "\n",
    "svr_c = 45\n",
    "svr_g = 40\n",
    "svr_pca_comp = 8\n",
    "svr_num_feat = 9\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#                               Main\n",
    "# ------------------------------------------------------------------------------\n",
    "def main():\n",
    "\n",
    "    # Prepare peptides for SVM\n",
    "    with open(svm_features_filename) as f:\n",
    "        svm_feat_dict = json.load(f)\n",
    "        svm_feat_dict = svm_feat_dict[0:svm_num_feat]#abre o arquivo json e carrega os dados aqui\n",
    "        \n",
    "    peptides_svm = pd.read_csv(training_filename)\n",
    "    peptides_svm.loc[(peptides_svm['MBIC'] > 64), 'MBIC'] = 0  #aqueles que têm mais de 64\n",
    "    peptides_svm.loc[(peptides_svm['MBIC'] != 0), 'MBIC'] = 1 # 1 aqueles que sao diferentes de 0\n",
    "\n",
    "    # Filter out columns based on feat list\n",
    "    labels = peptides_svm.columns.values.tolist() #colunas\n",
    "    for l in labels:\n",
    "        if l == 'MBIC': #coluna é MBIC \n",
    "            continue\n",
    "        if l not in svm_feat_dict: #remover a coluna apenas seleciona as que estão na lista de recursos selecionados svm_feat_dict qualquer coisa a mais é eliminada\n",
    "            peptides_svm = peptides_svm.drop(columns=[l])\n",
    "\n",
    "    y_svm = peptides_svm['MBIC'].to_numpy() #coluna mbic extraida e convertida num array\n",
    "    peptides_svm = peptides_svm.drop(columns=['MBIC']) #removida dos pepetidas_svm\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_norm_svm = min_max_scaler.fit_transform(peptides_svm) #restantes dados já sem a coluna mbic sao normalizados\n",
    "    pca_svm = PCA(n_components=svm_pca_comp) #criado um objeto PCA, ja com nº de componentes principais definidos\n",
    "    X_trans_svm = pca_svm.fit_transform(X_norm_svm)#aplicar o pca aos dados normalizados \n",
    "    SVC_rbf = SVC(kernel='rbf', C=svm_c, gamma=svm_g) #hiperparametros já defenidos  SVC(support vector classifier)\n",
    "    #classes 0 ou 1 , sendo 0 superior a 64\n",
    "\n",
    "    # Prepare peptides for SVR\n",
    "    with open(svr_features_filename) as f:\n",
    "        svr_feat_dict = json.load(f)\n",
    "        svr_feat_dict = svr_feat_dict[0:svr_num_feat]\n",
    "        \n",
    "    peptides_svr = pd.read_csv(training_filename)\n",
    "    peptides_svr, _ = seperatePeptides(peptides_svr, 64) # separar e parece que vamos contar so com aquels com mbic inferior ou = a 64\n",
    "        \n",
    "    # Filter out columns based on feat list\n",
    "    labels = peptides_svr.columns.values.tolist()\n",
    "    for l in labels:\n",
    "        if l == 'MBIC':\n",
    "            continue\n",
    "        if l not in svr_feat_dict:\n",
    "            peptides_svr = peptides_svr.drop(columns=[l])\n",
    "\n",
    "    y_svr = peptides_svr['MBIC'].to_numpy()\n",
    "    peptides_svr = peptides_svr.drop(columns=['MBIC']) #tirar oa mbic inferior a 64\n",
    "\n",
    "    min_max_scaler_svr = preprocessing.MinMaxScaler()\n",
    "    X_norm_svr = min_max_scaler_svr.fit_transform(peptides_svr)\n",
    "    pca_svr = PCA(n_components=svr_pca_comp) \n",
    "    X_trans_svr = pca_svr.fit_transform(X_norm_svr) \n",
    "    SVR_rbf = SVR(kernel='rbf', C=svr_c, gamma=svr_g) #agora é para svr e nao svm , saber melhor diferenciar isto!????\n",
    "    #svr numerico, sendo interessante mbic>64\n",
    "    #questão é: porque ter as duas abordagens por classes e numerico??\n",
    "    #questao é entao mas eles chamam teste mas estao a usar a mesma coisa que para o treinamento?\n",
    "\n",
    "    # Prepare test set of petides used by svr after training\n",
    "    peptides_test_svr = pd.read_csv(training_filename) #tem os dados todos i guess\n",
    "\n",
    "    # Filter out columns based on feat list\n",
    "    labels = peptides_test_svr.columns.values.tolist()\n",
    "    for l in labels:\n",
    "        if l == 'MBIC':\n",
    "            continue\n",
    "        if l not in svr_feat_dict:\n",
    "            peptides_test_svr = peptides_test_svr.drop(columns=[l])\n",
    "\n",
    "    y_svr2 = peptides_test_svr['MBIC'].to_numpy() #numerico\n",
    "    peptides_test_svr = peptides_test_svr.drop(columns=['MBIC']) #tira o mbic\n",
    "\n",
    "    # Apply svr transformations on test set of peptides for svr\n",
    "    X_norm_test_svr = min_max_scaler_svr.transform(peptides_test_svr)\n",
    "    X_trans_test_svr = pca_svr.transform(X_norm_test_svr)\n",
    "        \n",
    "    # Cross validation applied to full model\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats = 20)#dividir em 5 partes igualmente distribuidas\n",
    "    RMSE = []\n",
    "    cnt = 1\n",
    "    for train_index, test_index in rskf.split(X_trans_svm, y_svm):  \n",
    "        X_train, X_test = X_trans_svm[train_index], X_trans_svm[test_index]\n",
    "        y_train, y_test = y_svm[train_index], y_svm[test_index]\n",
    "        y_train = y_train.reshape(-1,1)\n",
    "        y_train = column_or_1d(y_train, warn=False)\n",
    "        svm_fit = SVC_rbf.fit(X_train, y_train)\n",
    "        y_pred = svm_fit.predict(X_test)\n",
    "        \n",
    "        train_index_svr = []\n",
    "        test_index_svr = []\n",
    "        y_train_svr = []\n",
    "        y_test_svr = []\n",
    "        for i in range(0, len(y_train)):\n",
    "            if(y_train[i] == 0):\n",
    "                continue\n",
    "            else:\n",
    "                train_index_svr.append(train_index[i]) #vai trabalhar apenas no 1 mbic de antibiofilm\n",
    "                \n",
    "        X_train_svr = X_trans_svr[train_index_svr]\n",
    "        y_train_svr = y_svr[train_index_svr]\n",
    "        svr_fit = SVR_rbf.fit(X_train_svr, y_train_svr)\n",
    "        \n",
    "        y_train_svr = []\n",
    "        for i in range(0, len(y_pred)):\n",
    "            if(y_pred[i] == 0):\n",
    "                continue\n",
    "            else:\n",
    "                test_index_svr.append(test_index[i])\n",
    "        \n",
    "        X_test_svr = X_trans_test_svr[test_index_svr]\n",
    "        y_test_svr = y_svr2[test_index_svr]\n",
    "        y_pred_svr = SVR_rbf.predict(X_test_svr)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_test_svr, y_pred_svr))\n",
    "\n",
    "        cnt = cnt + 1\n",
    "        \n",
    "        with open (svr_svm_results, 'a', encoding=\"utf-8\") as sfile:\n",
    "            sfile.write(str(rmse) + '\\n')\n",
    "        \n",
    "        RMSE.append(rmse)\n",
    "            \n",
    "    rmse_avg = np.average(RMSE)\n",
    "            \n",
    "    print('RMSE average: ' + str(rmse_avg))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "    #pelo que percebi vai tentar prever se é 0 ou 1 pelo svm e pelo svr avaliar o valor numerico correspondente sendo que p erro rmse estará disponobilizado\n",
    "    #  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
